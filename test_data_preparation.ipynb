{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e904d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from fourier_transform import extract_fft_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa894fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "list_files = ['Accelerometer.csv', 'Gyroscope.csv', 'Location.csv']\n",
    "base_data_dir = Path('test_data')\n",
    "resample_interval = \"1s\"\n",
    "anchor_time = pd.Timestamp(\"2025-01-01 00:00\")\n",
    "labels_to_include = ['train', 'biking', 'running']\n",
    "\n",
    "# Store processed labeled dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all relevant subdirectories\n",
    "for folder in base_data_dir.iterdir():\n",
    "    if folder.is_dir():\n",
    "        folder_name = folder.name.lower()\n",
    "        matched_label = next((label for label in labels_to_include if folder_name.startswith(label)), None)\n",
    "\n",
    "        if matched_label:\n",
    "            print(f\"Processing folder: {folder.name} (label = '{matched_label}')\")\n",
    "            folder_data = {}\n",
    "\n",
    "            for file_name in list_files:\n",
    "                file_path = folder / file_name\n",
    "                if file_path.exists():\n",
    "                    key = file_name.replace('.csv', '')\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    if 'Time (s)' not in df.columns:\n",
    "                        print(f\"Skipping {file_name} in {folder.name}: No 'Time (s)' column.\")\n",
    "                        continue\n",
    "\n",
    "                    # Convert time to timestamp\n",
    "                    df[\"timestamp\"] = anchor_time + pd.to_timedelta(df[\"Time (s)\"], unit=\"s\")\n",
    "                    df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "                    # Get numeric columns\n",
    "                    num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "                    # Interpolate\n",
    "                    df[num_cols] = df[num_cols].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "                    # Apply FFT to columns\n",
    "                    for col in num_cols:\n",
    "                        df = extract_fft_features(df, col, window_size=100, sampling_rate=100)\n",
    "\n",
    "                    # Resample and fill numeric + FFT features\n",
    "                    all_cols_to_resample = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "                    df_resampled = df[all_cols_to_resample].resample(resample_interval).mean()\n",
    "                    df_resampled = df_resampled.ffill().bfill()\n",
    "\n",
    "                    # Remove first and last row\n",
    "                    df_resampled = df_resampled.iloc[1:-1]\n",
    "\n",
    "                    folder_data[key] = df_resampled\n",
    "                    print(f\"  Loaded and resampled {file_name}\")\n",
    "                else:\n",
    "                    print(f\"  Missing {file_name} in {folder.name}\")\n",
    "\n",
    "            # Combine and label\n",
    "            if folder_data:\n",
    "                df_combined = pd.concat(folder_data.values(), axis=1)\n",
    "                df_combined['label'] = matched_label\n",
    "                df_combined.reset_index(inplace=True)\n",
    "                dataframes.append(df_combined)\n",
    "\n",
    "# Final merged dataset\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Drop all rows with any NaN values\n",
    "final_df = final_df.dropna()\n",
    "final_df = final_df.drop(columns=[col for col in final_df.columns if col == 'Time (s)'])\n",
    "print(f\"Final dataset shape after removing NaNs: {final_df.shape}\")\n",
    "print(\"Labels present:\", final_df['label'].value_counts())\n",
    "\n",
    "# Save to CSV in 'test_data' folder\n",
    "output_path = Path(\"test_data/final_test_data.csv\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved final_test_data to {output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a47c5",
   "metadata": {},
   "source": [
    "Adding patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d12b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = Path(\"data/final_data_with_patterns.csv\")\n",
    "TEST_SRC = Path(\"test_data/final_test_data.csv\")\n",
    "TEST_DST = Path(\"test_data/final_test_data_with_patterns.csv\")\n",
    "\n",
    "train_df = pd.read_csv(TRAIN, parse_dates=['timestamp'], index_col='timestamp')\n",
    "used_patterns = [col for col in train_df.columns if col in {\n",
    "    'sustained_low_speed',\n",
    "    'sustained_medium_speed',\n",
    "    'sustained_high_speed',\n",
    "    'low_velocity_high_gyro',\n",
    "    'high_velocity_low_gyro'\n",
    "}]\n",
    "\n",
    "# Load test data\n",
    "df = pd.read_csv(TEST_SRC, parse_dates=['timestamp'], index_col='timestamp')\n",
    "\n",
    "# Gyroscope magnitude\n",
    "df['gyro'] = np.sqrt(df['X (rad/s)']**2 + df['Y (rad/s)']**2 + df['Z (rad/s)']**2)\n",
    "df.drop(columns=['X (rad/s)', 'Y (rad/s)', 'Z (rad/s)'], inplace=True)\n",
    "\n",
    "# Drop GPS-related columns\n",
    "df.drop(columns=[\"Latitude (°)\", \"Longitude (°)\", \"Height (m)\", \"Horizontal Accuracy (m)\", \"Vertical Accuracy (°)\"], inplace=True)\n",
    "\n",
    "# Pattern definitions (same as training)\n",
    "PATTERN_FUNCTIONS = {\n",
    "    'sustained_low_speed': lambda df: (df['Velocity (m/s)'] < 0.5).rolling(window=10).sum() == 10,\n",
    "    'sustained_medium_speed': lambda df: df['Velocity (m/s)'].between(1.5, 3.0).rolling(window=10).sum() == 10,\n",
    "    'sustained_high_speed': lambda df: (df['Velocity (m/s)'] > 3.0).rolling(window=10).sum() == 10,\n",
    "    'low_velocity_high_gyro': lambda df: ((df['Velocity (m/s)'] < 0.5) & (df['gyro'].abs() > 1.0)).rolling(window=10).sum() == 10,\n",
    "    'high_velocity_low_gyro': lambda df: ((df['Velocity (m/s)'] > 3.0) & (df['gyro'].abs() < 0.5)).rolling(window=10).sum() == 10,\n",
    "}\n",
    "\n",
    "# Apply only the patterns used in train\n",
    "for name in used_patterns:\n",
    "    df[name] = PATTERN_FUNCTIONS[name](df).fillna(False)\n",
    "\n",
    "# Convert boolean columns to int for compatibility\n",
    "bool_cols = df.select_dtypes(include='bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "# Save\n",
    "df.to_csv(TEST_DST)\n",
    "print(f\"Test data with consistent pattern features saved to {TEST_DST}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
